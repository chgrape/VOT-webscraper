
# VOT-Webscraper

Това приложение взима снимки или текст от сайт и ги изобразява в търсачката на потребителя.




## Installation

Първо трябва машината да има изтеглен Docker-engine, който се използва за имплементиране на контейнеризация.

След това трябва да се настрои Docker Swarm, с който се имплементира висока отказоустойчивост.

За да може да могат отделните машини да си комуникират правилно, трябва следните портове да бъдат отворени: 2376/tcp, 2377/tcp, 7946/tcp, 7946/udp, 4789/udp, 22/tcp, 80/tcp. Всички машини трябва да са на една мрежа. Оттам три машини се избират за мениджъри на swarm-a докато останалите са работници. Единият мениджър се избира и му се подава следната команда:

```
docker swarm init --advertise-addr enp0s3
```

След което се присъединяват останалите машини с получения токен. 

```
docker swarm join --token "token" worker
```
Или за manager
```
docker swarm join --token "token" manager
```

След това с командата:
```
docker node ls
```
може да се видят всички присъединени машини


Трябва да сте създаде докер изображение с командата:
```
docker build -t vot-webscraper .
```
след което се пуска уеб приложението чрез:
```
docker stack deploy -c docker-compose.yml vot-webscraper
```

Тъй като приложението е контейнеризирано чрез Docker, може да се изпозлва командата scale за да може да се избере колко реплики да работят по приложението едновременно ето така:
```
docker service scale vot-webscraper_web=<номер на реплики>
```


За приложението трябва на машината да има инсталиран Python3 и чрез pip да бъдат изтеглени следните библиотеки:
```
pip install beautifulsoup4
pip install requests
```

После приложението може да бъде пуснатo с командата:
```
py main.py
```
Оттук може да се въведе линк към уебсайт и да се избере каква информация да бъде извлечена от него.



Сайтът, който се използва изобразяване на извлечената информация, се стартира на локалната мрежа и може да бъде достъпен от всяка търсачка на линк "http://localhost:80/".






